{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenVINO Video Inference on CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) 2019 Intel Corporation.\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining\n",
    "a copy of this software and associated documentation files (the\n",
    "\"Software\"), to deal in the Software without restriction, including\n",
    "without limitation the rights to use, copy, modify, merge, publish,\n",
    "distribute, sublicense, and/or sell copies of the Software, and to\n",
    "permit persons to whom the Software is furnished to do so, subject to\n",
    "the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be\n",
    "included in all copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\n",
    "EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n",
    "MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\n",
    "NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE\n",
    "LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION\n",
    "OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION\n",
    "WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective \n",
    "Transform your frozen graph into an intermediate representation (.bin/.xml) needed to use with OpenVINO then instantiate your OpenVINO model and inference live on a video file.\n",
    "\n",
    "# Activities \n",
    "**In this section of the training you will**\n",
    "- Create Intermediate Representation (.bin/.xml)\n",
    "- Understand OpenVINO Arguments\n",
    "- Instantiate OpenVINO Network\n",
    "- Use OpenCV to read video and pass frames to OpenVINO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Click the cell below and then click **Run**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import PIL\n",
    "import io\n",
    "import IPython.display\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Model Optimizer\n",
    "\n",
    "We're going to start by creating our Intermediate Representation (IR) using the OpenVINO Model Optimizer.  We're going to call out directly to the command line and look for the mo.py file.  We'll also pass in parameters for our input model and the input shape for our topology.  This command will, by default, generate the FP32 version of the IR, if you want to generate the FP16 version you need to add --data_type=FP16 to the parameters passed to mo.py.\n",
    "\n",
    "For more information on Model Optimizer please visit: https://docs.openvinotoolkit.org/latest/_docs_MO_DG_prepare_model_convert_model_Converting_Model.html \n",
    "\n",
    "Click the cell below and then click **Run**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!mo.py --input_model=tf_model/top_layers.iv3.pb --input_shape=[1,299,299,3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate Network\n",
    "\n",
    "Next, we'll instantiate our network.  If you want to take a closer look at all the specific steps required to instantitate the network look at the inference.py file included in this directory.  Instead, we're going to look at the parameters passed to the constructor.  We see the .XML file passed as the base model, no CPU extensions and targeting the CPU as the device type.\n",
    "\n",
    "Then we'll call out to the constructor for the Network instantiation. We then want to load our model into that network by passing in the above parameters to load_model. Lastly, we'll read in our labels file that we're going to use to decode the results during our inference.\n",
    "\n",
    "Click the cell below and then click **Run**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from inference import Network\n",
    "import sys\n",
    "\n",
    "arg_model=\"top_layers.iv3.xml\"\n",
    "arg_cpu_extension=None\n",
    "arg_device=\"CPU\"\n",
    "\n",
    "# Initialise the class\n",
    "infer_network = Network()\n",
    "# Load the network to IE plugin to get shape of input layer\n",
    "plugin, (n_fd, c_fd, h_fd, w_fd) = infer_network.load_model(arg_model, arg_device, 1, 1, 0, arg_cpu_extension)\n",
    "\n",
    "#Read in Labels\n",
    "arg_labels=\"iv3-labels.txt\"\n",
    "label_file = open(arg_labels, \"r\")\n",
    "labels = label_file.read().split('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for the inference!  There are 8 steps that we're doing in the code below:\n",
    "- Start a video or webcam capture\n",
    "- Read the video frame\n",
    "- Put the classification text on to the frame\n",
    "- Render the frame to the Cell output field\n",
    "- Resize/Transpose/Reshape/Preprocess frame\n",
    "- Start an inference request\n",
    "- Interpret the inference result\n",
    "- Clear frame from notebook cell\n",
    "\n",
    "Click the cell below and then click **Run**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.applications.inception_v3 import preprocess_input\n",
    "import time\n",
    "# Add the path to the video file you want to test with\n",
    "cap = cv2.VideoCapture(\"PATH_to_video_file.mp4\")\n",
    "pred_label = \"\"\n",
    "fps = 0\n",
    "ips = 0\n",
    "while True:\n",
    "    time1 = time.time()\n",
    "    ret, next_frame = cap.read()\n",
    "    \n",
    "    if ret:\n",
    "        next_frame = cv2.cvtColor(next_frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        cv2.putText(next_frame,str(pred_label) + \" \" + str(fps) + \"fps \" + str(ips) + \"ips\", (20,70), cv2.FONT_HERSHEY_SIMPLEX, 2, (255,255,2550), 4)\n",
    "        cv2.putText(next_frame,str(pred_label) + \" \" + str(fps) + \"fps \" + str(ips) + \"ips\", (20,70), cv2.FONT_HERSHEY_SIMPLEX, 2, (0,0,0), 2)\n",
    "\n",
    "        f = io.BytesIO()\n",
    "        PIL.Image.fromarray(next_frame).save(f, 'jpeg')\n",
    "        IPython.display.display(IPython.display.Image(data=f.getvalue()))\n",
    "\n",
    "        in_frame_fd = cv2.resize(next_frame, (w_fd, h_fd))\n",
    "        in_frame_fd = in_frame_fd.transpose((2, 0, 1))\n",
    "        in_frame_fd = in_frame_fd.reshape((n_fd, c_fd, h_fd, w_fd))\n",
    "        in_frame_fd = preprocess_input(in_frame_fd)\n",
    "\n",
    "        time3 = time.time()\n",
    "        # Start asynchronous inference for specified request\n",
    "        infer_network.exec_net(0, in_frame_fd)\n",
    "        # Wait for the result\n",
    "        infer_network.wait(0)\n",
    "        # Results of the output layer of the network\n",
    "        res = infer_network.get_output(0)\n",
    "        time4 = time.time()\n",
    "\n",
    "        top = res[0].argsort()[-1:][::-1]\n",
    "        pred_label = labels[top[0]]\n",
    "\n",
    "        time2 = time.time()\n",
    "        fps = '%.1f' % (1/(time2-time1))\n",
    "        ips = '%.1f' % (1/(time4-time3))\n",
    "\n",
    "        clear_output(wait=True)\n",
    "    else:\n",
    "        break\n",
    "\n",
    "clear_output(wait=True)\n",
    "print(\"Video Ended\")\n",
    "infer_network.clean()\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    " \n",
    "**In this section of the training you learned**\n",
    "- Create Intermediate Representation (.bin/.xml)\n",
    "- Understand OpenVINO Arguments\n",
    "- Instantiate OpenVINO Network\n",
    "- Use OpenCV to read video and pass frames to OpenVINO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_3.6_tf",
   "language": "python",
   "name": "python_3_6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
