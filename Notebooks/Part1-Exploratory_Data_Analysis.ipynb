{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notices**\n",
    "\n",
    "Copyright (c) 2019 Intel Corporation.\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining\n",
    "a copy of this software and associated documentation files (the\n",
    "\"Software\"), to deal in the Software without restriction, including\n",
    "without limitation the rights to use, copy, modify, merge, publish,\n",
    "distribute, sublicense, and/or sell copies of the Software, and to\n",
    "permit persons to whom the Software is furnished to do so, subject to\n",
    "the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be\n",
    "included in all copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\n",
    "EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n",
    "MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\n",
    "NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE\n",
    "LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION\n",
    "OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION\n",
    "WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling with VMMRdb on CPU\n",
    "\n",
    "## Objective\n",
    "\n",
    "Understand ways to find a data set and to prepare a data set for machine learning and training.\n",
    "\n",
    "## Activities \n",
    "**In this section of the training you will**\n",
    "- Fetch and visually inspect a dataset \n",
    "- Create a dataset to address a real life problem\n",
    "- Image Preprocessing\n",
    "- Data Augmentation Techniques\n",
    "- Address Imbalanced Dataset Problem\n",
    "- Organize a dataset into training, validation and testing groups\n",
    "- Finalize an augmented dataset for training, and testing\n",
    "\n",
    "As you follow this notebook, complete **Activity** sections to finish this workload. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Find a Data set\n",
    "\n",
    "Artificial intelligence projects depend upon data. When beginning a project, data scientists look for existing data sets that are similar to or match the given problem. This saves time and money, and leverages the work of others, building upon the body of knowledge for all future projects. \n",
    "\n",
    "Typically you begin with a search engine query. For this project, we were looking for a data set with an unencumbered license.\n",
    "\n",
    "This project starts with [Vehicle Make and Model Recognition Dataset (VMMRdb)](http://vmmrdb.cecsresearch.org/)   which is large in scale and diversity, containing 9,170 classes consisting of 291,752 images, covering models manufactured between 1950 to 2016. VMMRdb dataset contains images that were taken by different users, different imaging devices, and multiple view angles, ensuring a wide range of variations to account for various scenarios that could be encountered in a real-life scenario. The cars are not well aligned, and some images contain irrelevant background. The data covers vehicles from 712 areas covering all 412 sub-domains corresponding to US metro areas. VMMRdb dataset can be used as a baseline for training a robust model in several real-life scenarios for traffic surveillance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Subset of the Data\n",
    "\n",
    "Although we used the initial data set during our initial exploration, we are only providing a subset of the relevant data used for training.  This means that you don't have download an 11GB dataset but instead just use the existing data set provided with the notebook.  We maintained the original folder structure of the dataset but removed classes we're not utilizing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Hottest Wheels: The Most Stolen New And Used Cars In The U.S.\n",
    "\n",
    "![Create Dataset for Problem](assets/EDA_1-1.png)\n",
    "\n",
    "The most popular vehicle in America—at least among thieves—is neither a rip-roaring sports car nor a plush luxury sedan. Heck, it’s not even an SUV. Instead, the most stolen vehicle is a plain vanilla 1996 Honda Civic that otherwise gets lost in a crowded parking lot. A total of 45,052 older-model Civics were pilfered last year. Among brand-new vehicles, another average family car tops the list, the Nissan Altima. Some 1,153 Altimas from the 2017 model year were taken last year.\n",
    "\n",
    "Here are the 10 most stolen used cars according to the NICB, with the most “popular” model year noted along with the total number of units from all model years taken:\n",
    "\n",
    "- Honda Civic (1998): 45,062\n",
    "- Honda Accord (1997): 43,764\n",
    "- Ford F-150 (2006): 35,105\n",
    "- Chevrolet Silverado (2004): 30.056\n",
    "- Toyota Camry (2017): 17,276\n",
    "- Nissan Altima (2016):  13,358\n",
    "- Toyota Corolla (2016): 12,337\n",
    "- Dodge/Ram Pickup (2001): 12,004\n",
    "- GMC Sierra (2017): 10,865\n",
    "- Chevrolet Impala (2008): 9,487\n",
    "\n",
    "### 1.4 Select and Merge Interested Classes\n",
    "\n",
    "In this section, we're going to look at merging cars that are the same Make/Model but look at the years nearby since cars usually look the same for 3-4 years before changing styles.  Below we'll see a dictionary containing the base car we're looking for and all the relevant cars that we're going to include in that category.\n",
    "\n",
    "Honda Civic (1998): 45,062\t        -> Honda Civic (1997 - 1998)\n",
    "Honda Accord (1997): 43,764\t        -> Honda Accord (1996 - 1997)\n",
    "Ford F-150 (2006): 35,105\t        -> Ford F150 (2005 - 2007)\n",
    "Chevrolet Silverado (2004): 30,056\t-> Chevrolet Silverado (2003 - 2004)\n",
    "Toyota Camry (2017): 17,276         -> Toyota Camry (2012 - 2014)\n",
    "Nissan Altima (2016):  13,358       -> Nissan Altima (2013 - 2015)\n",
    "Toyota Corolla (2016): 12,337       -> Toyota Corolla (2011 - 2013)\n",
    "Dodge/Ram Pickup (2001): 12,004\t    -> Dodge Ram 1500 (1995 - 2001)\n",
    "GMC Sierra (2017): 10,865           -> GMC Sierra 1500 (2007 - 2013)\n",
    "Chevrolet Impala (2008): 9,487\t    -> Chevrolet Impala (2007 - 2009)\n",
    "\n",
    "After merging the directories appropriately we're going take a look at a random subset of images in each of the categories.\n",
    "\n",
    "Click the cell below and then click **Run**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import vmmr_utils\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "cars = {\n",
    "    \"honda_civic_1998\": [\"honda_civic_1997\", \"honda_civic_1998\"], # available \"honda_civic_1999\"\n",
    "    \"honda_accord_1997\": [\"honda_accord_1996\", \"honda_accord_1997\"],\n",
    "    \"ford_f150_2006\": [\"ford_f150_2005\", \"ford_f150_2006\", \"ford_f150_2007\"],\n",
    "    \"chevrolet_silverado_2004\": [\"chevrolet_silverado_2003\", \"chevrolet_silverado_2004\"], # available \"chevrolet_silverado_2005\"\n",
    "    \"toyota_camry_2014\": [\"toyota_camry_2012\", \"toyota_camry_2013\", \"toyota_camry_2014\", \"toyota_camry_le_2012\", \"toyota_camry_le_2013\", \"toyota_camry_le_2014\", \"toyota_camry_se_2012\", \"toyota_camry_se_2013\", \"toyota_camry_xle_2012\", \"toyota_camry_xle_2013\"],\n",
    "    \"nissan_altima_2014\": [\"nissan_altima_2013\", \"nissan_altima_2014\", \"nissan_altima_2015\"],\n",
    "    \"toyota_corolla_2013\": [\"toyota_corolla_2011\", \"toyota_corolla_2012\", \"toyota_corolla_2013\", \"toyota_corolla_ce_2012\", \"toyota_corolla_le_2012\", \"toyota_corolla_le_2013\", \"toyota_corolla_s_2011\", \"toyota_corolla_s_2012\"],\n",
    "    \"dodge_ram_2001\": [\"dodge_ram_1500_2000\", \"dodge_ram_1500_2001\", \"dodge_ram_1500_1999\", \"dodge_ram_1500_1998\", \"dodge_ram_1500_1997\", \"dodge_ram_1500_1996\", \"dodge_ram_1500_1995\"],\n",
    "    \"gmc_sierra_2012\": [\"gmc_sierra_1500_2007\", \"gmc_sierra_1500_2008\", \"gmc_sierra_1500_2009\", \"gmc_sierra_1500_2010\", \"gmc_sierra_1500_2011\", \"gmc_sierra_1500_2012\", \"gmc_sierra_1500_2013\", \"gmc_sierra_2500_2007\", \"gmc_sierra_2500_2008\", \"gmc_sierra_2500_2009\", \"gmc_sierra_2500_2010\", \"gmc_sierra_2500_2011\", \"gmc_sierra_2500_2012\", \"gmc_sierra_2500_2013\"],\n",
    "    \"chevrolet_impala_2008\": [\"chevrolet_impala_2007\", \"chevrolet_impala_2008\", \"chevrolet_impala_2009\"]\n",
    "}\n",
    "\n",
    "\n",
    "full_dataset_path = \"../Dataset/SubsetVMMR\"\n",
    "stolen_cars_path = \"../Dataset/Most_Stolen_Cars\"\n",
    "\n",
    "if os.path.exists(stolen_cars_path):\n",
    "    shutil.rmtree(stolen_cars_path)\n",
    "else:\n",
    "    os.makedirs(stolen_cars_path)\n",
    "\n",
    "for directory, car_list in cars.items():\n",
    "    print(\"Creating\", directory)\n",
    "    car_directory_name = os.path.join(stolen_cars_path, directory)\n",
    "    os.makedirs(car_directory_name)\n",
    "    for car in car_list:\n",
    "        path = os.path.join(full_dataset_path, car, \"\")\n",
    "        files = glob.glob(path + '*.jpg')\n",
    "        for file in files:\n",
    "            shutil.copy(file, car_directory_name)\n",
    "\n",
    "vmmr_utils.display_images(stolen_cars_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Remove Invalid, Corrupt and Non-JPG files\n",
    "\n",
    "![Clean images](assets/EDA_1-2.png)\n",
    "\n",
    "In this section, we remove images that are not in \".jpg\" format or that can not be read by cv2 module. We're utilizing the multiprocessing function so that we can take advantage of all of the cores on our machine to make the process go quickly\n",
    "\n",
    "Click the cell below and then click **Run**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "#Check Images\n",
    "if __name__ == '__main__':\n",
    "    pool = Pool()\n",
    "    image_list = glob.glob(stolen_cars_path + \"/*/*\")\n",
    "    pool.map(vmmr_utils.check_image, image_list)\n",
    "    pool.close()\n",
    "\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Distribution of Selected Classes\n",
    "\n",
    "![View Data Distribution](assets/EDA_1-3.png)\n",
    "\n",
    "Now, we can take a look at the class distribution of our problem statement. We're importing PyGal and creating a wrapper for rendering the chart inline, then passing in our data to the charting function.\n",
    "\n",
    "Click the cell below and then click **Run**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pygal'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-fcf21834c2b1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpygal\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mHTML\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#Create function to display interactive plotting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m base_html = \"\"\"\n\u001b[0;32m      5\u001b[0m \u001b[1;33m<\u001b[0m\u001b[0;31m!\u001b[0m\u001b[0mDOCTYPE\u001b[0m \u001b[0mhtml\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pygal'"
     ]
    }
   ],
   "source": [
    "import pygal \n",
    "from IPython.display import display, HTML\n",
    "#Create function to display interactive plotting\n",
    "base_html = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "  <head>\n",
    "  <script type=\"text/javascript\" src=\"http://kozea.github.com/pygal.js/javascripts/svg.jquery.js\"></script>\n",
    "  <script type=\"text/javascript\" src=\"https://kozea.github.io/pygal.js/2.0.x/pygal-tooltips.min.js\"\"></script>\n",
    "  </head>\n",
    "  <body>\n",
    "    <figure>\n",
    "      {rendered_chart}\n",
    "    </figure>\n",
    "  </body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "def galplot(chart):\n",
    "    rendered_chart = chart.render(is_unicode=True)\n",
    "    plot_html = base_html.format(rendered_chart=rendered_chart)\n",
    "    display(HTML(plot_html))\n",
    "    \n",
    "#Compare class distribution\n",
    "line_chart = pygal.Bar(height=300)\n",
    "line_chart.title = 'Stolen Car Class Distribution'\n",
    "for o in os.listdir(stolen_cars_path):\n",
    "    line_chart.add(o, len(os.listdir(os.path.join(stolen_cars_path, o))))\n",
    "galplot(line_chart)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Confirm Folder Structure is Correct\n",
    "\n",
    "To summarize and confirm our progress, we can take a look at the folder tree structure in **Most_Stolen_Cars** to take a look at our images we used to create a smaller subset. \n",
    "\n",
    "Click the cell below and then click **Run**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confirm Folder Structure\n",
    "for root, dirs, files in os.walk(stolen_cars_path):\n",
    "    level = root.replace(os.getcwd(), '').count(os.sep)\n",
    "    print('{0}{1}/'.format('    ' * level, os.path.basename(root)))\n",
    "    for f in files[:2]:\n",
    "        print('{0}{1}'.format('    ' * (level + 1), f))\n",
    "    if level is not 0:\n",
    "        print('{0}{1}'.format('    ' * (level + 1), \"...\"))        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Train, Validation and Test Folders\n",
    "\n",
    "![Create Data Folders](assets/EDA_1-4.png)\n",
    "\n",
    "We need to create training, validation and test folders for data ingestion and we'll use 0.7, 0.1, 0.2 ratio for this purpose.\n",
    "\n",
    "Click the cell below and then click **Run**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import re\n",
    "import sys\n",
    "\n",
    "#Train and Test Set Variables\n",
    "train_val_test_ratio = (.7,.1,.2) # 70/10/20 Data Split\n",
    "test_folder = '../Dataset/test/'\n",
    "train_folder = '../Dataset/train/'\n",
    "val_folder = '../Dataset/val/'\n",
    "\n",
    "file_names = os.listdir('../Dataset/Most_Stolen_Cars')\n",
    "\n",
    "#Remove Existing Folders if they exist\n",
    "for folder in [test_folder, train_folder, val_folder]:\n",
    "    if os.path.exists(folder) and os.path.isdir(folder):\n",
    "        shutil.rmtree(folder)\n",
    "\n",
    "#Remake Category Folders in both Train and Test Folders\n",
    "for category in file_names:\n",
    "    os.makedirs(test_folder + category)\n",
    "    os.makedirs(train_folder + category)\n",
    "    os.makedirs(val_folder + category)\n",
    "\n",
    "#Split Data by Train Ratio and copy files to correct directory\n",
    "for idx, category in enumerate(file_names):\n",
    "    file_list = os.listdir(stolen_cars_path + '/' + category)\n",
    "    \n",
    "    train_ratio = math.floor(len(file_list) * train_val_test_ratio[0])\n",
    "    val_ratio = math.floor(len(file_list) * train_val_test_ratio[1])\n",
    "    train_list = file_list[:train_ratio]\n",
    "    val_list = file_list[train_ratio:train_ratio + val_ratio]\n",
    "    test_list = file_list[train_ratio + val_ratio:]\n",
    "    \n",
    "    for i, file in enumerate(train_list):\n",
    "        shutil.copy(stolen_cars_path + '/' + category + '/' + file, train_folder + '/' + category + '/' + file)\n",
    "    sys.stdout.write('Moving %s train images to category folder %s' % (len(train_list), category))  \n",
    "    sys.stdout.write('\\n')\n",
    "    for i, file in enumerate(val_list):\n",
    "        shutil.copy(stolen_cars_path + '/' + category + '/' + file, val_folder + '/' + category + '/' + file)\n",
    "    sys.stdout.write('Moving %s validation images to category folder %s' % (len(val_list), category))                   \n",
    "    sys.stdout.write('\\n')\n",
    "    for i, file in enumerate(test_list):\n",
    "        shutil.copy(stolen_cars_path + '/' + category + '/' + file, test_folder + '/' + category + '/' + file)\n",
    "    sys.stdout.write('Moving %s test images to category folder %s' % (len(test_list), category))\n",
    "    sys.stdout.write('\\n')\n",
    "    \n",
    "print(\"Done.\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Augmentation\n",
    "\n",
    "While looking at our distribution above we saw that certain classes were significantly lower than others.  To help mitigate that issue we're going to augment some of our data set so that we have a dataset that is more closely distributed.  Below we're taking a look at an example image and showing the effets of augmentation given a certain threshold of modification.  Then we're going to apply these random augmentations to our data.\n",
    "\n",
    "Click the cell below and then click **Run**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "#Select a random image and follow the next step\n",
    "datagen = ImageDataGenerator(rotation_range=45, \n",
    "                             width_shift_range=0.2, \n",
    "                             height_shift_range=0.2, \n",
    "                             zoom_range=0.3, \n",
    "                             vertical_flip=True,\n",
    "                             horizontal_flip=True, \n",
    "                             fill_mode=\"nearest\")\n",
    "#Load example image\n",
    "file_list = glob.glob(\"../Dataset/test/*/*\")\n",
    "img_path = random.choice(file_list)\n",
    "img = load_img(img_path)\n",
    "car_class = img_path.split(\"/\")[1]\n",
    "plt.imshow(img)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Original \" + car_class, fontsize=16)\n",
    "\n",
    "img = img_to_array(img)\n",
    "img = img.reshape((1,) + img.shape)\n",
    "#Apply different augmentation techniques\n",
    "n_augmentations = 4\n",
    "plt.figure(figsize=(15, 6))    \n",
    "i = 0\n",
    "for batch in datagen.flow(img, \n",
    "                          batch_size=1, \n",
    "                          seed=21):\n",
    "    \n",
    "    plt.subplot(2, int(np.ceil(n_augmentations * 1. / 2)), i + 1)\n",
    "    plt.imshow(array_to_img(batch[0]))\n",
    "    plt.axis(\"off\")\n",
    "    plt.suptitle(\"Augmented \" + car_class, fontsize=16)    \n",
    "    \n",
    "    i += 1\n",
    "    if i >= n_augmentations:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finalize Augmented Dataset for Training \n",
    "\n",
    "![Data Augmentation](assets/EDA_1-5.png)\n",
    "\n",
    "By using the augmentation techniques we have learned, we can oversample minority classes in training set. We are not going to do these steps in validation or test in order not to create any bias on the data. \n",
    "\n",
    "**Activity**\n",
    "\n",
    "Click the cell below and then click **Run**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Oversampling Minority Classes in Training Set\n",
    "def data_augment(data_dir):\n",
    "    list_of_images = os.listdir(data_dir)\n",
    "    datagen = ImageDataGenerator(rotation_range=45, \n",
    "        horizontal_flip=True, \n",
    "        fill_mode=\"nearest\")\n",
    "    for img_name in list_of_images:\n",
    "        tmp_img_name = os.path.join(data_dir, img_name)\n",
    "        img = load_img(tmp_img_name)\n",
    "        img = img_to_array(img)\n",
    "        img = img.reshape((1,) + img.shape)\n",
    "\n",
    "        batch = datagen.flow(img, \n",
    "            batch_size=1, \n",
    "            seed=21,\n",
    "            save_to_dir=data_dir, \n",
    "            save_prefix=img_name.split(\".jpg\")[0] + \"augmented\", \n",
    "            save_format=\"jpg\")\n",
    "\n",
    "        batch.next()\n",
    "\n",
    "classes_to_augment = [\n",
    "    \"toyota_camry_2014\",\n",
    "    \"nissan_altima_2014\",\n",
    "    \"toyota_corolla_2013\",\n",
    "    \"gmc_sierra_2012\"]\n",
    "\n",
    "for class_names in classes_to_augment:\n",
    "    print(\"Currently Augmenting:\", class_names)\n",
    "    data_dir = os.path.join(train_folder, class_names)\n",
    "    data_augment(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resize Images\n",
    "\n",
    "![Resize Images](assets/EDA_1-6.png)\n",
    "\n",
    "Depending on the toplogy, we need to resize the images with the expected image format. Since we're going to be using InceptionV3 in the next section we're going to match the size, 299x299, for that topology. \n",
    "\n",
    "**Activity**\n",
    "\n",
    "Click the cell below and then click **Run**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "#Resize Images\n",
    "if __name__ == '__main__':\n",
    "    pool = Pool()\n",
    "    image_list = glob.glob(train_folder + \"/*/*\")\n",
    "    func = partial(vmmr_utils.resize_image, size=299)\n",
    "    pool.map(func, image_list)\n",
    "    pool.close()\n",
    "\n",
    "vmmr_utils.display_images(train_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at Distribution of Selected Classes again\n",
    "\n",
    "![View New Data Distribution](assets/EDA_1-7.png)\n",
    "\n",
    "Now that we've done some augmentation to the dataset we want to see how the distribution has changed compared to before the augmentation.  In this case we're only going to be looking at the train folder, since we only augmented the train dataset, so the numbers will be slightly lower than the full dataset distribution graph from earlier.  \n",
    "\n",
    "Click the cell below and then click **Run**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compare class distribution\n",
    "line_chart = pygal.Bar(height=300)\n",
    "line_chart.title = 'Most Stolen Car Training Class Distribution'\n",
    "for o in os.listdir(train_folder):\n",
    "    line_chart.add(o, len(os.listdir(os.path.join(train_folder, o))))\n",
    "galplot(line_chart)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary \n",
    "**In this section of the training you learned**\n",
    "- Fetch and visually inspect a dataset \n",
    "- Create a dataset to address a real life problem\n",
    "- Image Preprocessing and Data Augmentation Techniques\n",
    "- Address Imbalanced Dataset Problem\n",
    "- Organize a dataset into training, validation and testing groups\n",
    "- Finalize an augmented dataset for training, and testing\n",
    "\n",
    "You now should understand ways to find a data set and to prepare a data set for machine learning and training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Citations\n",
    "\n",
    "A Large and Diverse Dataset for Improved Vehicle Make and Model Recognition\n",
    "F. Tafazzoli, K. Nishiyama and H. Frigui\n",
    "In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Workshops 2017. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (intel_dc2edge)",
   "language": "python",
   "name": "intel_dc2edge"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
